<!DOCTYPE html><html><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>traffic-sign-detection | CS Blog</title><link rel="stylesheet" type="text/css" href="/css/normalize.css"><link rel="stylesheet" type="text/css" href="/css/highlight.css"><link rel="stylesheet" type="text/css" href="/css/very-simple.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/font-awesome/4.5.0/css/font-awesome.min.css"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"></head><body><!-- include the sidebar--><!-- include ./includes/sidebar.jade--><!-- Blog title and subtitle--><header><div class="container header"><a id="logo" href="/." class="title">CS Blog</a><span class="subtitle">AI ML 自耕農</span><label id="toggle-menu" for="menu" onclick><i class="fa fa-bars"></i></label></div></header><!-- use checkbox hack for toggle nav-bar on small screens--><input id="menu" type="checkbox"><!-- Navigation Links--><nav id="nav"><div class="container"><a href="/" class="sidebar-nav-item active">Home</a><a href="/archives" class="sidebar-nav-item">Archives</a></div></nav><div id="header-margin-bar"></div><!-- gallery that comes before the header--><div class="wrapper"><div class="container post-header"><h1>traffic-sign-detection</h1></div></div><div class="wrapper"><div class="container meta"><div class="post-time">2017-01-18</div><div class="post-categories"><a class="post-category-link" href="/categories/ML/">ML</a></div><div class="post-tags"><a class="post-tag-link" href="/tags/CNN/">CNN</a>/<a class="post-tag-link" href="/tags/Deep-Learning/">Deep Learning</a>/<a class="post-tag-link" href="/tags/ML/">ML</a></div></div></div><article><div class="container post"><h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>終於來到 project 2 了, 這次的主要目的是練習使用 tensorflow 做交通號誌識別<br>Dataset 為 <strong><a href="http://benchmark.ini.rub.de/?section=gtsrb&amp;subsection=dataset" target="_blank" rel="external">German Traffic Sign Dataset</a></strong><br>有43種交通號誌, 是一種43選1的概念, 因為沒有考慮<strong>都不是</strong>這個選項, 所以通常這類問題較簡單, 有researcher達到<a href="https://medium.com/@vivek.yadav/improved-performance-of-deep-learning-neural-network-models-on-traffic-sign-classification-using-6355346da2dc#.fey4taais" target="_blank" rel="external">99.81%</a>的辨識率<br>共 51839 張 training data, 而 testing 有 12630 張, 分佈如下, 可以看的出來資料分佈不均<br><img src="/2017/01/18/traffic-sign-detection/data_distribution.png" alt="data-distribution"><br>每種類別 random 挑一張出來如下圖<br><img src="/2017/01/18/traffic-sign-detection/allTrafficSign.png" alt="43-classes"><br>Udacity 很好心的幫忙把所有的 image 幫你打包成只剩下 traffic sign <a href="https://d17h27t6h515a5.cloudfront.net/topher/2016/November/581faac4_traffic-signs-data/traffic-signs-data.zip" target="_blank" rel="external">Download</a>, 且 cv2.resize(image,(32,32)) 了, 只需要 pickle.load 下來就搞定<br>而原始的 data 是給你一大張image, 然後再告訴你那些traffic signs在image中的rectangular window座標, 還要再多處理較麻煩</p>
<p>要注意的一點是, dataset 是經由一秒鐘的 video 擷取下來, 因此鄰近的 data 會很相近 [1], 如果使用 train_test_split 會 random 選擇, 導致 train 和 validation 會相近而看不出差異</p>
<h3 id="Input-Data-Preprocessing"><a href="#Input-Data-Preprocessing" class="headerlink" title="Input Data Preprocessing"></a>Input Data Preprocessing</h3><p>Udacity 建議我們可以處理幾個方向</p>
<ol>
<li>將 data 數量弄得較 balance<br>  NN 算 loss 的時候不會根據每個類別數量的多寡作權重, 因此最單純的方法是就想辦法產生出一樣多的數量, 如第2點</li>
<li><p>可以增加 fake data<br>  我的 image processing 實在很弱, 只單純的使用 rotation, 而且只敢稍微讓angle為正負5度, 怕那種有方向箭頭的號誌轉壞</p>
  <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">cv2.getRotationMatrix2D(image_center, angle, scale)</div></pre></td></tr></table></figure>
<p>  這樣的方式我實驗起來其實沒啥幫助, XD<br>  我看到有人還使用 cv2.WarpPerspective, 果然專業多了! 我相信產生種類夠多的 fake data 一定會有幫助, 例如加 noise, blur 等等</p>
</li>
<li>將 data 做 normalization<br>  做語音習慣了, 直覺就用 guassian normalization, mean=0, var=1, 結果整個大失敗! 只有不到1%辨識率, why??<br>  後來用 mean substraction, 然後除 abs 的最大值, 我只選擇使用 YUV 的 Y channel 當 input</li>
</ol>
<h3 id="CNN-架構"><a href="#CNN-架構" class="headerlink" title="CNN 架構"></a>CNN 架構</h3><p>要設計和調整架構有點花時間, 加上我時間不多(<del>懶</del>), 所以我直接就用LeNet架構<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">layer_depth = &#123;</div><div class="line">    &apos;layer_1&apos;: 6,</div><div class="line">    &apos;layer_2&apos;: 16,</div><div class="line">    &apos;fully_connected_1&apos;: 120,</div><div class="line">    &apos;fully_connected_2&apos;: 84,</div><div class="line">    &apos;out&apos;: n_classes,</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>自己多加了 <strong>dropout</strong> 和 <strong>l2 regularization</strong>, 原因是每次跑 training 的 accuracy 都要標到98 99, 但是 validation set 始終很難突破 93, 一直有 overfit 的感覺<br>tensorflow 的 dropout 是設定要保留多少比例 (keep_prob), 在 training 的時候設定在最後的兩層 fully connected layers, keep_prob 基本上愈難訓練也需要愈多 epoch<br>另外記得在做 evaluation 的時候要把 keep_prob 設定成 1</p>
<p>[1] 的架構想法不錯, 將較低層的 conv. layer 和較上層的 conv. layer 一併當作 fully connected layer 的 input, 這樣同時能夠有 low-level feature, higher-resolution 和 high-level feature, lower-resolution 兩種資訊一起當決策<br><img src="/2017/01/18/traffic-sign-detection/CNN.png" alt="Traffic-sign-CNN"></p>
<h3 id="其他-Hyper-parameters"><a href="#其他-Hyper-parameters" class="headerlink" title="其他 Hyper-parameters"></a>其他 Hyper-parameters</h3><ul>
<li>Optimizer: 說實話, 要不停的調整出最好的參數實在沒那個心力, 所以與其用SGD, 我就直接用 <strong>Adam</strong> 了 (<strong>Adagrad</strong>也是一種懶人選擇)</li>
<li>pooling: 沒啥特別選, 因此用 max-pooling</li>
<li>batch-size: 原先設定128, 有一次改成256就實在train不好, 就退回128了</li>
<li>learning rate: 0.001</li>
<li>l2 weight: 0.01</li>
</ul>
<h3 id="Learning-Performance"><a href="#Learning-Performance" class="headerlink" title="Learning Performance"></a>Learning Performance</h3><p><img src="/2017/01/18/traffic-sign-detection/train_validation_performance.png" alt="train_validation_performance"><br>test set accuracy = 0.893</p>
<h3 id="自選測試圖片"><a href="#自選測試圖片" class="headerlink" title="自選測試圖片"></a>自選測試圖片</h3><p>Udacity希望能學員自己找圖片來測試, 因此我就在德國的 google map 上找圖, (看著看著心都飄過去了)<br><img src="/2017/01/18/traffic-sign-detection/from_google_map.png" alt="20-test-from-google-map"><br>20張圖辨識結果如下:<br><img src="/2017/01/18/traffic-sign-detection/from_google_map_performance.png" alt="from_google_map_performance"><br>剛好錯10個, 只有 50% 正確率, 這實在有點悲劇<br>其中有兩個錯誤值得注意<br><img src="/2017/01/18/traffic-sign-detection/error_traffic_signal.png" alt="error_traffic_signal"><br>右圖是top5辨識到的類別及機率, 可以發現除了正確答案的 traffic signal 在第二名外, 第一名的 general causion 其實跟 traffic signal 超像的 (只看灰階)<br>看來必須把 input 的<strong>色彩資訊</strong>也加進去才能進一步改善了<br>另一個是如下<br><img src="/2017/01/18/traffic-sign-detection/error_speed_limit_30.png" alt="error_speed_limit_30"><br>這個錯誤自己分析的原因是因為 training data 的 speed limit 都是圓的外框, 而此case剛好是一個長方形牌子, 裡面才是退色很嚴重的圓形, 所以導致辨識失敗<br>或許真的 train 得很好的 CNN 有能力找出重要的判斷資訊, 因此會去忽略外面的方框, 而選擇去”看”外面退色的圓形和裡面的數字<br>結論就是, 應該是我自己沒train好吧 ?!</p>
<h3 id="短結"><a href="#短結" class="headerlink" title="短結"></a>短結</h3><p>小小做過一輪交通號誌辨識, 才比較有感覺真實狀況會有多困難阿~<br>找時間來 visualize 一下每層的 hidden units 對什麼樣的 image 會有較高的 activation! <a href="http://www.matthewzeiler.com/pubs/arxive2013/eccv2014.pdf" target="_blank" rel="external">This paper by Zeiler and Fergus</a> with <a href="https://www.youtube.com/watch?v=ghEmQSxT6tw" target="_blank" rel="external">toolbox</a></p>
<blockquote>
<p>要能 train 出好 model 除了參考文獻培養對 model 架構的好直覺外, engineering 的苦工也會是很大的關鍵!</p>
</blockquote>
<h3 id="後續嘗試"><a href="#後續嘗試" class="headerlink" title="後續嘗試"></a>後續嘗試</h3><p>對於目前的辨識率很不滿意阿! 不死心下就實作[1]的架構, 然後將 NN 的 model size 擴大, 並且將顏色資訊 YUV 的 U 加進去訓練 (結果上述因顏色錯誤的traffic signal就分對了)<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"># Hyper-parameters</div><div class="line">EPOCHS = 30</div><div class="line">BATCH_SIZE = 128</div><div class="line">rate = 0.001</div><div class="line">drop_out_keep_prob = 0.5</div><div class="line"></div><div class="line">layer_depth = &#123;</div><div class="line">    &apos;layer_1&apos;: 16,</div><div class="line">    &apos;layer_2&apos;: 32,</div><div class="line">    &apos;fully_connected_1&apos;: 256,</div><div class="line">    &apos;fully_connected_2&apos;: 128,</div><div class="line">    &apos;out&apos;: n_classes,</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>得到了 <strong>Test Accuracy = 0.953</strong> ! 但是自選圖雖有進步仍很低 <strong>65%</strong><br>另外, 上述的參數設定下, 如果加了 l2_weight = 0.01 的話, validation 只能到 0.91x, 實在不大好訓練, 後來只好放棄<br>第一次的 submission, reviewer 給了一些不錯的 reference 如下:</p>
<blockquote>
<h3 id="Extra-Important-Material"><a href="#Extra-Important-Material" class="headerlink" title="Extra Important Material"></a>Extra Important Material</h3><p>Lately on slack few students asked for a good Deep Learning book.So after lot of research found a book which is also recommended by Elon Musk</p>
<ul>
<li>Deep Learning (Adaptive Computation and Machine Learning series) <a href="https://github.com/HFTrader/DeepLearningBook" target="_blank" rel="external">Github</a> and on <a href="https://www.amazon.com/dp/0262035618/ref=wl_it_dp_o_pC_nS_ttl?_encoding=UTF8&amp;colid=2OAQEZHVOXV7K&amp;coliid=I5UEVIG1ZB9LU" target="_blank" rel="external">Amazon</a></li>
<li><a href="http://www.fast.ai/" target="_blank" rel="external">Fast.ai</a></li>
<li><a href="http://yerevann.com/a-guide-to-deep-learning/" target="_blank" rel="external">A Guide to Deep Learning</a><h3 id="Few-Articles"><a href="#Few-Articles" class="headerlink" title="Few Articles"></a>Few Articles</h3></li>
<li><a href="https://medium.com/@vivek.yadav/improved-performance-of-deep-learning-neural-network-models-on-traffic-sign-classification-using-6355346da2dc#.rb0345kna" target="_blank" rel="external">Traffic sign classification using brightness augmentation</a></li>
<li><a href="https://medium.com/@vivek.yadav/dealing-with-unbalanced-data-generating-additional-data-by-jittering-the-original-image-7497fe2119c3#.4uro6h6uw" target="_blank" rel="external">Dealing with unbalanced data</a><h3 id="Extra-Materials"><a href="#Extra-Materials" class="headerlink" title="Extra Materials"></a>Extra Materials</h3></li>
<li>I noted a <a href="http://stats.stackexchange.com/questions/140811/how-large-should-the-batch-size-be-for-stochastic-gradient-descent" target="_blank" rel="external">linkage here</a> to discuss about how should we choose the batch_size of Stochastic Gradient Decent</li>
<li>Since you might be interested into “Adam Optimizer”, here is a <a href="http://sebastianruder.com/optimizing-gradient-descent/index.html#adam" target="_blank" rel="external">website</a> that talks about it.</li>
<li>You might like to learn the whole idea of <a href="https://pgaleone.eu/deep-learning/regularization/2017/01/10/anaysis-of-dropout/" target="_blank" rel="external">Dropout</a> It’s gives a brief analysis of the technique.</li>
</ul>
</blockquote>
<p><strong>reviewer 很用心阿!棒棒!</strong></p>
<hr>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p>[1.] <a href="https://www.google.com.tw/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;cad=rja&amp;uact=8&amp;ved=0ahUKEwiTqsb8-8vRAhUBopQKHafVC4oQFggbMAA&amp;url=http%3A%2F%2Fyann.lecun.com%2Fexdb%2Fpublis%2Fpdf%2Fsermanet-ijcnn-11.pdf&amp;usg=AFQjCNEtvdz_vnI9tg1wF96UcjxVYwxdHw" target="_blank" rel="external">Traffic Sign Recognition with Multi-Scale Convolutional Networks</a></p>
</div><!-- comment system--><div class="container"><hr></div></article><footer id="footer"><div class="container"><div class="bar"><div class="social"><a href="/atom.xml" target="_blank"><i class="fa fa-rss"></i></a></div><div class="footer">© 2017 <a href="/" rel="nofollow">Bobon</a>. Powered by <a rel="nofollow" target="_blank" href="https://hexo.io">Hexo</a>. Theme <a target="_blank" href="https://github.com/lotabout/very-simple">very-simple</a>.</div></div></div></footer><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.css"><script src="//cdn.bootcss.com/jquery/2.0.3/jquery.min.js"></script><script src="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.pack.js"></script><script>$(document).ready(function() {
    $(".fancybox").fancybox();
});
</script></body></html>